# üåê Agente Web Scraper Intelligente

Un progetto didattico di livello **intermedio** per imparare a costruire agenti AI che interagiscono con il web. Questo agente pu√≤ cercare informazioni online, estrarre dati da siti web e sintetizzare risultati in modo intelligente.

---

## üéØ Obiettivi di Apprendimento

Questo progetto ti insegna concetti avanzati degli agenti AI:

### 1. **Tool Calling (Function Calling)**
Come l'agente decide QUALE strumento usare per risolvere un compito:
- Analisi della query utente
- Selezione del tool appropriato
- Chiamata dello strumento con parametri corretti
- Gestione dei risultati

### 2. **Web Interaction**
Come l'agente interagisce con il mondo esterno:
- Ricerca su web (Google/Bing)
- Scraping di pagine HTML
- Parsing e pulizia dati
- Gestione errori di rete

### 3. **Chain of Thought (CoT)**
Come l'agente "pensa" prima di agire:
- Ragionamento esplicito sui passi da seguire
- Pianificazione multi-step
- Auto-correzione se un approccio fallisce

### 4. **Information Synthesis**
Come l'agente combina informazioni da fonti multiple:
- Aggregazione dati
- Rimozione duplicati
- Sintesi e riassunto
- Citazione delle fonti

### 5. **Gestione Asincrona**
Come gestire operazioni che richiedono tempo:
- Richieste HTTP asincrone
- Rate limiting
- Timeout e retry logic
- Caching dei risultati

---

## üóÇÔ∏è Struttura del Progetto

```
web-scraper-agent/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ CODICE PRINCIPALE
‚îÇ   ‚îú‚îÄ‚îÄ agent.py                 # Agente principale con tool calling
‚îÇ   ‚îú‚îÄ‚îÄ web_tools.py            # Tools per web search e scraping
‚îÇ   ‚îú‚îÄ‚îÄ html_parser.py          # Parser HTML intelligente
‚îÇ   ‚îú‚îÄ‚îÄ llm_interface.py        # Interfaccia unificata per LLM
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # CLI interattiva
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Dipendenze
‚îÇ
‚îú‚îÄ‚îÄ üìö CONFIGURAZIONE
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml             # Configurazione agente e tools
‚îÇ   ‚îî‚îÄ‚îÄ .env.example            # Template variabili ambiente
‚îÇ
‚îú‚îÄ‚îÄ üß™ TESTING
‚îÇ   ‚îú‚îÄ‚îÄ test_agent.py           # Test dell'agente
‚îÇ   ‚îú‚îÄ‚îÄ test_tools.py           # Test dei singoli tools
‚îÇ   ‚îî‚îÄ‚îÄ test_integration.py     # Test end-to-end
‚îÇ
‚îú‚îÄ‚îÄ üìñ DOCUMENTAZIONE
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Questa guida
‚îÇ   ‚îú‚îÄ‚îÄ TUTORIAL.md             # Tutorial passo-passo
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md         # Architettura dettagliata
‚îÇ   ‚îî‚îÄ‚îÄ EXAMPLES.md             # Esempi pratici
‚îÇ
‚îî‚îÄ‚îÄ üìÅ ESEMPI
    ‚îú‚îÄ‚îÄ queries/                # Query di esempio
    ‚îî‚îÄ‚îÄ cached_results/         # Cache risultati per testing
```

---

## üõ†Ô∏è Tools Implementati

L'agente ha accesso a diversi "tools" (strumenti) specializzati:

### 1. **search_web(query: str, num_results: int)**
```python
"""
Cerca informazioni sul web usando un motore di ricerca.

Quando usarlo:
- Query informative ("Chi √® Elon Musk?")
- Ricerca di notizie recenti
- Trovare fonti su un topic

Esempio:
>>> search_web("Ultime novit√† AI 2024", num_results=5)
[
  {
    "title": "Le 10 innovazioni AI del 2024",
    "url": "https://...",
    "snippet": "Quest'anno ha visto progressi..."
  },
  ...
]
"""
```

**Tecnologie**: API DuckDuckGo/SerpAPI/Google Custom Search

### 2. **fetch_webpage(url: str)**
```python
"""
Scarica e parsifica il contenuto di una pagina web.

Quando usarlo:
- Estrarre contenuto da URL specifico
- Leggere articoli completi
- Analizzare pagine web

Esempio:
>>> fetch_webpage("https://example.com/article")
{
  "title": "Titolo articolo",
  "content": "Testo completo pulito...",
  "author": "Mario Rossi",
  "date": "2024-01-15",
  "links": [...]
}
"""
```

**Tecnologie**: requests, BeautifulSoup4, readability-lxml

### 3. **extract_structured_data(html: str, schema: dict)**
```python
"""
Estrae dati strutturati da HTML usando selettori CSS.

Quando usarlo:
- Estrarre tabelle
- Scaricare liste di prodotti
- Parsing dati strutturati

Esempio:
>>> extract_structured_data(html, {
...   "products": {
...     "selector": ".product-card",
...     "fields": {
...       "name": ".product-name",
...       "price": ".product-price"
...     }
...   }
... })
[{"name": "Laptop", "price": "999.99"}, ...]
"""
```

**Tecnologie**: BeautifulSoup4, CSS selectors, XPath

### 4. **summarize_content(text: str, max_length: int)**
```python
"""
Riassume testo lungo usando l'LLM.

Quando usarlo:
- Sintetizzare articoli lunghi
- Estrarre punti chiave
- Creare abstract

Esempio:
>>> summarize_content(long_article, max_length=200)
"L'articolo discute 3 punti principali: 1) ..."
"""
```

**Tecnologie**: LLM (Ollama/OpenAI)

### 5. **compare_sources(sources: List[str])**
```python
"""
Confronta informazioni da fonti multiple.

Quando usarlo:
- Fact-checking
- Identificare consenso/disaccordo
- Cross-reference

Esempio:
>>> compare_sources([url1, url2, url3])
{
  "consensus": "Tutti concordano che...",
  "differences": "Fonte 1 afferma X, Fonte 2 afferma Y",
  "reliability": {"source1": 0.9, "source2": 0.7}
}
"""
```

**Tecnologie**: LLM reasoning, similarity metrics

---

## üß† Architettura dell'Agente

### Il Ciclo Tool Calling

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    UTENTE FA UNA QUERY                      ‚îÇ
‚îÇ   "Trova le ultime notizie su SpaceX e riassumile"         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 1: ANALISI QUERY                                      ‚îÇ
‚îÇ  L'agente analizza la richiesta e identifica:              ‚îÇ
‚îÇ  - Intent: "ricerca + sintesi"                              ‚îÇ
‚îÇ  - Entit√†: "SpaceX", "notizie"                             ‚îÇ
‚îÇ  - Azioni necessarie: [search, fetch, summarize]           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 2: PIANIFICAZIONE (Chain of Thought)                 ‚îÇ
‚îÇ  L'agente crea un piano:                                    ‚îÇ
‚îÇ  1. search_web("SpaceX news 2024", num=5)                  ‚îÇ
‚îÇ  2. fetch_webpage(top_3_results)                            ‚îÇ
‚îÇ  3. summarize_content(combined_articles)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 3: ESECUZIONE TOOLS                                   ‚îÇ
‚îÇ  Per ogni tool nel piano:                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ 3a. Valida parametri                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 3b. Esegui tool                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 3c. Gestisci errori/retry                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ 3d. Memorizza risultato                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 4: SINTESI FINALE                                     ‚îÇ
‚îÇ  L'agente combina i risultati dei tools e genera           ‚îÇ
‚îÇ  una risposta coerente citando le fonti                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    RISPOSTA ALL'UTENTE                      ‚îÇ
‚îÇ  "Ecco le ultime notizie su SpaceX:                        ‚îÇ
‚îÇ   1. Lancio Starship... [fonte: ...]                       ‚îÇ
‚îÇ   2. Contratto NASA... [fonte: ...]                        ‚îÇ
‚îÇ   Riassunto: ..."                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componenti Chiave

#### 1. **ToolRegistry**
```python
class ToolRegistry:
    """
    Registro di tutti i tools disponibili.
    Gestisce registrazione, discovery e invocazione.
    """
    
    def register_tool(self, name: str, function: Callable, 
                     description: str, parameters: dict):
        """Registra un nuovo tool"""
        
    def get_tool_descriptions(self) -> str:
        """Genera descrizioni per il prompt LLM"""
        
    def call_tool(self, name: str, **kwargs) -> Any:
        """Esegue un tool con validazione"""
```

#### 2. **WebScraperAgent**
```python
class WebScraperAgent:
    """
    Agente principale che orchestra i tools.
    """
    
    def __init__(self, llm_model: str = "llama3.2"):
        self.llm = LLMInterface(llm_model)
        self.tools = ToolRegistry()
        self.memory = ConversationMemory()
        
    def process_query(self, query: str) -> str:
        """
        Pipeline principale:
        1. Analizza query
        2. Genera piano
        3. Esegue tools
        4. Sintetizza risultato
        """
        
    def _generate_plan(self, query: str) -> List[ToolCall]:
        """Chain of Thought: pianifica azioni"""
        
    def _execute_plan(self, plan: List[ToolCall]) -> List[Any]:
        """Esegue il piano step-by-step"""
        
    def _synthesize_results(self, results: List[Any]) -> str:
        """Combina risultati in risposta finale"""
```

#### 3. **LLMInterface**
```python
class LLMInterface:
    """
    Interfaccia unificata per diversi LLM.
    Supporta: Ollama, OpenAI, Anthropic.
    """
    
    def generate(self, prompt: str, system: str = None) -> str:
        """Generazione semplice"""
        
    def chat(self, messages: List[Dict]) -> str:
        """Conversazione con contesto"""
        
    def function_call(self, query: str, 
                     tools: List[Dict]) -> Dict:
        """Tool calling nativo (se supportato)"""
```

---

## üîÑ Flusso di Esecuzione Dettagliato

### Esempio: "Confronta i prezzi dei laptop su 3 siti"

```python
# 1. ANALISI QUERY
agent.process_query("Confronta i prezzi dei laptop su Amazon, eBay e MediaWorld")

# Internamente l'agente:

# 2. PIANIFICAZIONE
plan = [
    ToolCall("search_web", {"query": "laptop prices Amazon"}),
    ToolCall("search_web", {"query": "laptop prices eBay"}),
    ToolCall("search_web", {"query": "laptop prices MediaWorld"}),
    ToolCall("fetch_webpage", {"url": result1.url}),
    ToolCall("fetch_webpage", {"url": result2.url}),
    ToolCall("fetch_webpage", {"url": result3.url}),
    ToolCall("extract_structured_data", {
        "html": page1,
        "schema": laptop_schema
    }),
    # ... stessa cosa per page2 e page3
    ToolCall("compare_sources", {"sources": [data1, data2, data3]})
]

# 3. ESECUZIONE
results = agent._execute_plan(plan)
# [search_results, ..., comparison]

# 4. SINTESI
final_response = agent._synthesize_results(results)
# "Ho confrontato i prezzi su 3 siti:
#  - Amazon: Laptop X a ‚Ç¨899 [link]
#  - eBay: Laptop X a ‚Ç¨850 [link]
#  - MediaWorld: Laptop X a ‚Ç¨920 [link]
#  Migliore offerta: eBay (-‚Ç¨49 vs Amazon)"
```

---

## üìã Requisiti e Installazione

### Prerequisiti

```bash
# Python 3.8+
python --version

# Ollama (per LLM locale)
ollama --version

# Variabili ambiente (opzionale)
# Per API esterne: Google Custom Search, SerpAPI, etc.
```

### Installazione

```bash
# 1. Clone/Download progetto
cd web-scraper-agent

# 2. Installa dipendenze
pip install -r requirements.txt

# 3. Configura (opzionale)
cp .env.example .env
# Edita .env con le tue API keys

# 4. Configura tools
# Edita config.yaml per abilitare/disabilitare tools

# 5. Scarica modello LLM
ollama pull llama3.2

# 6. Test setup
python test_agent.py
```

### Dipendenze Principali

```txt
# LLM
ollama                    # LLM locale
openai                    # OpenAI API (opzionale)
anthropic                 # Claude API (opzionale)

# Web Scraping
requests                  # HTTP client
beautifulsoup4            # HTML parsing
lxml                      # XML/HTML parser veloce
readability-lxml          # Estrazione contenuto principale
selenium                  # Browser automation (opzionale)

# Search
duckduckgo-search        # Search senza API key
google-api-python-client # Google Custom Search (opzionale)

# Utilities
pyyaml                    # Config files
python-dotenv             # Variabili ambiente
validators                # Validazione URL
tqdm                      # Progress bars
tenacity                  # Retry logic

# Testing
pytest                    # Framework testing
pytest-asyncio            # Test asincroni
responses                 # Mock HTTP requests
```

---

## üíª Utilizzo

### CLI Interattiva

```bash
python main.py
```

```
üåê AGENTE WEB SCRAPER INTELLIGENTE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Comandi disponibili:
  search <query>        - Cerca sul web
  fetch <url>          - Scarica una pagina
  extract <url>        - Estrai dati strutturati
  compare <urls>       - Confronta pi√π fonti
  help                 - Mostra aiuto
  exit                 - Esci

üí¨ Tu: search ultime notizie AI Italia

ü§î Analizzo la richiesta...
üìã Piano:
  1. search_web("AI news Italy 2024")
  2. fetch_webpage(top_3_results)
  3. summarize_content(combined)

‚öôÔ∏è  Esecuzione...
‚úì search_web completato (5 risultati)
‚úì fetch_webpage completato (3 pagine)
‚úì summarize_content completato

ü§ñ Risposta:
Ho trovato 5 articoli recenti sull'AI in Italia:

1. "Investimenti AI crescono del 40%" - Il Sole 24 Ore
   https://...
   Sintesi: Le aziende italiane hanno aumentato...

2. "Milano hub europeo AI" - Corriere della Sera
   https://...
   Sintesi: Milano si posiziona come...

[Fonti consultate: 3 articoli, ultimo aggiornamento: oggi]
```

### Uso Programmatico

```python
from agent import WebScraperAgent

# Inizializza agente
agent = WebScraperAgent(
    llm_model="llama3.2",
    max_tools_per_query=5,
    enable_caching=True
)

# Query semplice
result = agent.query("Qual √® il prezzo attuale del Bitcoin?")
print(result)

# Query complessa con tool multipli
result = agent.query(
    "Trova le migliori offerte di voli Milano-New York per Dicembre, "
    "confronta 3 siti diversi e dammi i pro/contro di ciascuna opzione"
)
print(result)

# Accesso allo storico
print(agent.get_execution_history())
# [
#   {
#     "query": "...",
#     "plan": [...],
#     "tools_executed": [...],
#     "result": "...",
#     "timestamp": "..."
#   }
# ]
```

---

## üéì Concetti Avanzati

### 1. Chain of Thought (CoT) Prompting

```python
# L'agente usa CoT per pianificare azioni
cot_prompt = f"""
Query utente: {user_query}

Pensa step-by-step a come rispondere:

1. Qual √® l'obiettivo della query?
2. Quali informazioni servono?
3. Quali tools posso usare?
4. In che ordine li uso?
5. Come combino i risultati?

Genera un piano di azione in JSON:
{{
  "reasoning": "...",
  "steps": [
    {{"tool": "search_web", "params": {{}}, "why": "..."}},
    ...
  ]
}}
"""
```

### 2. Tool Selection

```python
# L'agente decide quale tool usare
def select_tool(self, intent: str, context: dict) -> str:
    """
    Euristiche per selezione tool:
    
    - "cerca", "trova" ‚Üí search_web
    - URL specifico ‚Üí fetch_webpage
    - "confronta", "differenze" ‚Üí compare_sources
    - "riassumi", "sintetizza" ‚Üí summarize_content
    - "estrai tabella", "lista" ‚Üí extract_structured_data
    """
    
    # Oppure usa LLM per decidere
    decision_prompt = f"""
    Dato l'intent '{intent}' e il contesto {context},
    quale tool √® pi√π appropriato?
    
    Tools disponibili:
    {self.tools.get_descriptions()}
    
    Rispondi con il nome del tool e perch√©.
    """
```

### 3. Error Handling & Retry

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class WebTools:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        reraise=True
    )
    def fetch_webpage(self, url: str) -> dict:
        """
        Retry automatico in caso di:
        - Network errors
        - Timeout
        - 5xx errors
        """
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return self._parse_html(response.text)
```

### 4. Result Caching

```python
class CachedTools:
    """
    Cache risultati per evitare richieste duplicate
    """
    
    def __init__(self, cache_dir: str = ".cache"):
        self.cache = {}
        self.cache_dir = cache_dir
    
    def search_web(self, query: str, **kwargs) -> List[dict]:
        # Crea cache key
        cache_key = hashlib.md5(
            f"{query}{kwargs}".encode()
        ).hexdigest()
        
        # Check cache
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # Esegui ricerca
        results = self._do_search(query, **kwargs)
        
        # Salva in cache
        self.cache[cache_key] = results
        return results
```

---

## üß™ Testing

### Test Unitari

```bash
# Test singoli tools
pytest test_tools.py -v

# Test agente
pytest test_agent.py -v

# Test integration
pytest test_integration.py -v

# Coverage
pytest --cov=. --cov-report=html
```

### Test Esempio

```python
def test_search_tool():
    """Test search_web tool"""
    tools = WebTools()
    
    results = tools.search_web("Python programming", num_results=5)
    
    assert len(results) == 5
    assert all("url" in r for r in results)
    assert all("title" in r for r in results)
    
def test_agent_planning():
    """Test che l'agente generi un piano sensato"""
    agent = WebScraperAgent()
    
    query = "Trova i migliori ristoranti a Roma"
    plan = agent._generate_plan(query)
    
    # Dovrebbe usare search_web
    assert any(step.tool == "search_web" for step in plan)
    
def test_end_to_end():
    """Test completo query ‚Üí risultato"""
    agent = WebScraperAgent()
    
    result = agent.query("Qual √® la capitale della Francia?")
    
    assert "parigi" in result.lower()
    assert len(agent.execution_history) > 0
```

---

## üìñ Esempi Pratici

### Esempio 1: Ricerca e Sintesi

```python
# Query: "Ultimi sviluppi sulla fusione nucleare"

# Piano generato:
# 1. search_web("nuclear fusion breakthrough 2024")
# 2. fetch_webpage(top_3_results)
# 3. summarize_content(combined_text)

# Risultato:
"""
Ho trovato 3 articoli recenti sulla fusione nucleare:

1. "Record energetico al NIF" - Nature
   https://nature.com/...
   Il National Ignition Facility ha raggiunto un guadagno netto...

2. "ITER anticipa timeline" - Science
   https://science.org/...
   Il reattore ITER potrebbe essere operativo prima del...

Sintesi: Progressi significativi sia negli USA (NIF) che in Europa (ITER)...

[Consultate 3 fonti | Ultimo aggiornamento: 2 ore fa]
"""
```

### Esempio 2: Confronto Prodotti

```python
# Query: "Confronta iPhone 15 vs Samsung S24"

# Piano:
# 1. search_web("iPhone 15 specs review")
# 2. search_web("Samsung S24 specs review")
# 3. fetch_webpage(official_spec_pages)
# 4. extract_structured_data(specs_tables)
# 5. compare_sources([iphone_data, samsung_data])

# Risultato:
"""
Confronto iPhone 15 vs Samsung Galaxy S24:

DISPLAY:
- iPhone 15: 6.1" OLED 2556x1179 [fonte: apple.com]
- Samsung S24: 6.2" AMOLED 2340x1080 [fonte: samsung.com]
‚Üí Vantaggio: iPhone (risoluzione superiore)

FOTOCAMERA:
- iPhone 15: 48MP principale + 12MP ultra-wide
- Samsung S24: 50MP principale + 12MP ultra-wide + 10MP tele
‚Üí Vantaggio: Samsung (lente aggiuntiva)

PREZZO:
- iPhone 15: ‚Ç¨979 [fonte: amazon.it]
- Samsung S24: ‚Ç¨899 [fonte: unieuro.it]
‚Üí Vantaggio: Samsung (‚Ç¨80 meno costoso)

RACCOMANDAZIONE: Dipende dalle priorit√†...
"""
```

### Esempio 3: Analisi Tendenze

```python
# Query: "Analizza le tendenze del mercato AI negli ultimi 3 mesi"

# Piano:
# 1. search_web("AI market trends Q4 2024")
# 2. search_web("AI investment news october november december 2024")
# 3. fetch_webpage(industry_reports)
# 4. extract_structured_data(investment_figures)
# 5. summarize_content(trend_analysis)

# Risultato con grafici testuali
"""
TENDENZE MERCATO AI - Q4 2024

INVESTIMENTI:
Ottobre: $12.5B ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë
Novembre: $15.2B ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë
Dicembre: $18.1B ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (nuovo record)

TOP SETTORI:
1. Healthcare AI: $5.2B (+45% vs Q3)
2. Enterprise AI: $4.8B (+32%)
3. Autonomous Systems: $3.1B (+28%)

INSIGHTS CHIAVE:
‚Ä¢ Crescita accelerata del 44% rispetto a Q3
‚Ä¢ Focus su AI generativa per enterprise
‚Ä¢ Europa supera Asia in investimenti per prima volta

[Fonti: 12 report analizzati | Periodo: Ott-Dic 2024]
"""
```

---

## üöÄ Estensioni e Miglioramenti

### Livello Intermedio

- [ ] **Multi-language support**: Ricerca in lingue diverse
- [ ] **Image search**: Integra ricerca immagini
- [ ] **PDF extraction**: Scarica e analizza PDF
- [ ] **API integration**: Weather, finance, news APIs

### Livello Avanzato

- [ ] **Async execution**: Parallelizza richieste web
- [ ] **Browser automation**: Usa Selenium per siti dinamici
- [ ] **ML-based extraction**: Usa NLP per estrarre entities
- [ ] **Knowledge graph**: Costruisci grafo delle informazioni

### Livello Produzione

- [ ] **Web UI**: Frontend React/Streamlit
- [ ] **Authentication**: Sistema di login
- [ ] **API REST**: Esponi agente via API
- [ ] **Database**: Salva queries e risultati
- [ ] **Monitoring**: Metrics, logging, alerting

---

## ‚ö†Ô∏è Limitazioni e Note Legali

### Limitazioni Tecniche

- Rate limiting dei siti web
- Siti con JavaScript pesante (serve Selenium)
- CAPTCHAs e anti-bot measures
- Paywall e contenuti protetti

### Note Legali

‚öñÔ∏è **IMPORTANTE**: Rispetta sempre:

- `robots.txt` dei siti web
- Terms of Service
- Rate limits
- Copyright e propriet√† intellettuale
- Privacy e GDPR

**Questo progetto √® SOLO per scopi educativi.**

---

## ü§ù Confronto con Progetto 1

| Aspetto | Progetto 1 (File Agent) | Progetto 2 (Web Scraper) |
|---------|------------------------|--------------------------|
| **Complessit√†** | Base | Intermedio |
| **Tools** | 1 (file reading) | 5+ (web tools) |
| **I/O** | File system | Internet |
| **Errori** | File not found | Network, timeout, parsing |
| **Caching** | Non necessario | Essenziale |
| **Async** | No | Consigliato |
| **Tool Selection** | Fisso | Dinamico |
| **Planning** | Singolo step | Multi-step |

---

## üìö Risorse Utili

- **Web Scraping**: https://realpython.com/beautiful-soup-web-scraper-python/
- **Tool Calling**: https://platform.openai.com/docs/guides/function-calling
- **BeautifulSoup Docs**: https://www.crummy.com/software/BeautifulSoup/
- **Requests Docs**: https://requests.readthedocs.io/
- **Async Python**: https://realpython.com/async-io-python/

---

## üéØ Prossimi Passi

Dopo questo progetto, puoi passare al **Progetto 3: Sistema Multi-Agente** che combina:
- Pi√π agenti specializzati
- Orchestrazione e comunicazione inter-agente
- Task delegation
- Collaborative problem solving

---

**Buon coding! üöÄ**

*Ricorda: questo √® un progetto didattico. Usa responsabilmente le tecniche apprese e rispetta sempre i ToS dei servizi che usi.*
